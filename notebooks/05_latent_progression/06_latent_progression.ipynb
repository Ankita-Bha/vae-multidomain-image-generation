{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ad65a7",
   "metadata": {},
   "source": [
    "# Latent Space Learning Progression\n",
    "\n",
    "Purpose: Visualize how a fixed latent vector is decoded at different\n",
    "training stages of the VAE to observe representation stabilization.\n",
    "\n",
    "This notebook uses saved VAE checkpoints only.\n",
    "No classifiers or evaluations are involved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb96903",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from src.models.vae import VAE  # your existing VAE implementation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032749e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset to visualize (change only this if you want another dataset)\n",
    "DATASET = \"mnist\"   # options: \"mnist\", \"fashion\", \"emnist\"\n",
    "\n",
    "# Where VAE checkpoints are stored\n",
    "CHECKPOINT_DIR = \"../checkpoints/grayscale\"\n",
    "\n",
    "# Epochs whose checkpoints exist as .pt files\n",
    "EPOCHS_TO_VISUALIZE = [1, 10, 50, 100]\n",
    "\n",
    "# Latent dimension used during VAE training\n",
    "LATENT_DIM = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d72c04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)  # reproducibility\n",
    "\n",
    "z_fixed = torch.randn(1, LATENT_DIM).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e208884",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_vae_checkpoint(epoch):\n",
    "    ckpt_path = f\"{CHECKPOINT_DIR}/{DATASET}_epoch_{epoch}.pt\"\n",
    "\n",
    "    if not Path(ckpt_path).exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "\n",
    "    vae = VAE(latent_dim=LATENT_DIM).to(device)\n",
    "    vae.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    vae.eval()\n",
    "    return vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5648b8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "decoded_images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for epoch in EPOCHS_TO_VISUALIZE:\n",
    "        vae = load_vae_checkpoint(epoch)\n",
    "        img = vae.decode(z_fixed)\n",
    "        decoded_images.append(img.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937717b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "\n",
    "for i, img in enumerate(decoded_images):\n",
    "    plt.subplot(1, len(decoded_images), i + 1)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"Epoch {EPOCHS_TO_VISUALIZE[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Latent Progression for {DATASET.upper()}\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d62c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"../outputs/progression\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "for i, img in enumerate(decoded_images):\n",
    "    plt.subplot(1, len(decoded_images), i + 1)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"Epoch {EPOCHS_TO_VISUALIZE[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Latent Progression for {DATASET.upper()}\")\n",
    "plt.savefig(output_dir / f\"{DATASET}_latent_progression.png\", dpi=200)\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
