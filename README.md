
- **Reconstruction Loss** ensures fidelity to input images
- **KL Divergence** enforces a structured, continuous latent space
- The Î² parameter controls the trade-off between:
  - visual clarity
  - latent space regularization

---

## Latent Space Analysis
A key component of this project is **latent traversal**, where:

- One latent dimension is varied at a time
- All other dimensions are held constant
- Resulting image changes are observed

This analysis demonstrates that:
- The latent space is continuous
- Individual latent dimensions encode meaningful visual factors
- Changes are smooth and interpretable, not random

---

## Image Generation Results
- The model is capable of generating new images by sampling from the latent space
- Generated images are slightly blurred, which is a known characteristic of VAEs
- This behavior arises from:
  - low-resolution datasets
  - pixel-wise reconstruction objectives
  - probabilistic decoding

Images may be upscaled for visualization purposes only; generation occurs at the original resolution.

---

## Project Status
Current progress includes:
- CNN-based VAE implemented and trained
- Latent space traversal and analysis completed
- Image generation validated
- Results documented with clear limitations and observations

---

## Research Significance
This project demonstrates:
- Effective unsupervised representation learning
- Interpretable latent space structure
- Controlled image generation
- Awareness of fundamental trade-offs in generative modeling

These aspects align closely with research themes in **representation learning** and **unsupervised deep learning**.

---

## Future Work
Potential extensions include:
- CNN-based VAE with classification head
- Conditional Variational Autoencoders
- Higher-resolution datasets (e.g., CelebA)
- Comparative studies with GANs or diffusion models

---

## Reproducibility Notes
- Datasets and trained model weights are excluded from version control
- The repository contains only source code and documentation
- Experiments can be reproduced by retraining locally

---

## Author
**Ankita**  
Computer Science | Machine Learning & Representation Learning
